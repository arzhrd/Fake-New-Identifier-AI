{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvcKFA0GZvERZIc1/XHLKp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arzhrd/Fake-New-Identifier-AI/blob/main/Fake_News_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bctVWvxcuHxw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class FakeNewsPredictor:\n",
        "    def __init__(self, model_path='fake_news_model.pkl'):\n",
        "        \"\"\"Initialize the predictor with saved model\"\"\"\n",
        "        try:\n",
        "\n",
        "            try:\n",
        "                nltk.data.find('corpora/stopwords')\n",
        "            except LookupError:\n",
        "                nltk.download('stopwords')\n",
        "\n",
        "            with open(model_path, 'rb') as file:\n",
        "                model_data = pickle.load(file)\n",
        "\n",
        "            self.model = model_data['model']\n",
        "            self.vectorizer = model_data['vectorizer']\n",
        "            self.model_name = model_data['model_name']\n",
        "\n",
        "            print(f\"Loaded {self.model_name} model successfully!\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Model file '{model_path}' not found!\")\n",
        "            print(\"Please run 'train_model.py' first to create the model.\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            raise\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Clean and preprocess text data\"\"\"\n",
        "        if pd.isna(text) or text is None:\n",
        "            return \"\"\n",
        "\n",
        "\n",
        "        text = str(text).lower()\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = text.split()\n",
        "        filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "\n",
        "        stemmer = PorterStemmer()\n",
        "        stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "        return ' '.join(stemmed_words)\n",
        "\n",
        "    def predict_single_news(self, text):\n",
        "        \"\"\"Predict if a single news article is fake or real\"\"\"\n",
        "        try:\n",
        "\n",
        "            processed_text = self.preprocess_text(text)\n",
        "\n",
        "            if not processed_text.strip():\n",
        "                return {\n",
        "                    'error': 'Empty or invalid text provided',\n",
        "                    'prediction': None,\n",
        "                    'confidence': None\n",
        "                }\n",
        "\n",
        "\n",
        "            text_tfidf = self.vectorizer.transform([processed_text])\n",
        "\n",
        "\n",
        "            prediction = self.model.predict(text_tfidf)[0]\n",
        "            probabilities = self.model.predict_proba(text_tfidf)[0]\n",
        "\n",
        "\n",
        "            result = {\n",
        "                'original_text': text,\n",
        "                'prediction': 'Fake' if prediction == 1 else 'Real',\n",
        "                'confidence': max(probabilities),\n",
        "                'probabilities': {\n",
        "                    'Real': probabilities[0],\n",
        "                    'Fake': probabilities[1]\n",
        "                },\n",
        "                'model_used': self.model_name\n",
        "            }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error': f'Prediction error: {e}',\n",
        "                'prediction': None,\n",
        "                'confidence': None\n",
        "            }\n",
        "\n",
        "    def predict_batch_news(self, news_list):\n",
        "        \"\"\"Predict multiple news articles at once\"\"\"\n",
        "        results = []\n",
        "\n",
        "        for i, news_text in enumerate(news_list):\n",
        "            print(f\"Processing article {i+1}/{len(news_list)}...\")\n",
        "            result = self.predict_single_news(news_text)\n",
        "            results.append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def predict_from_file(self, file_path, text_column='text'):\n",
        "        \"\"\"Predict news from a CSV file\"\"\"\n",
        "        try:\n",
        "\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            if text_column not in df.columns:\n",
        "                return f\"Error: Column '{text_column}' not found in the file.\"\n",
        "\n",
        "\n",
        "            predictions = []\n",
        "            confidences = []\n",
        "            fake_probs = []\n",
        "\n",
        "            print(f\"Processing {len(df)} articles from file...\")\n",
        "\n",
        "            for idx, text in enumerate(df[text_column]):\n",
        "                if idx % 50 == 0:  # Progress indicator\n",
        "                    print(f\"Processed {idx}/{len(df)} articles...\")\n",
        "\n",
        "                result = self.predict_single_news(text)\n",
        "\n",
        "                if result.get('error'):\n",
        "                    predictions.append('Error')\n",
        "                    confidences.append(0)\n",
        "                    fake_probs.append(0)\n",
        "                else:\n",
        "                    predictions.append(result['prediction'])\n",
        "                    confidences.append(result['confidence'])\n",
        "                    fake_probs.append(result['probabilities']['Fake'])\n",
        "\n",
        "\n",
        "            df['predicted_label'] = predictions\n",
        "            df['confidence'] = confidences\n",
        "            df['fake_probability'] = fake_probs\n",
        "\n",
        "\n",
        "            output_file = file_path.replace('.csv', '_predictions.csv')\n",
        "            df.to_csv(output_file, index=False)\n",
        "\n",
        "            print(f\"Predictions saved to: {output_file}\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing file: {e}\"\n"
      ]
    }
  ]
}